# Project Log

## 2025-12-11 (Evening)

*   **Deployment Automation:**
    *   Created a new PowerShell script `deploy-to-github.ps1` to serve as an "end-of-day" task. This script automates staging all changes (`git add .`), committing them locally (with an optional custom message), and then pushing all local commits to the remote GitHub repository. This facilitates the user's preferred workflow of batching changes and testing locally before deployment.

## 2025-12-11 (Afternoon)

*   **Automated Website Navigation:**
    *   Significantly enhanced `build_menu.py` to automatically generate the `nav` section of `mkdocs.yml`. The script now scans the `drafts` and `evidence` directories and builds a hierarchical menu, removing the need for manual updates.
*   **Refined Processing Workflow:**
    *   Modified `run-pqq-manager.ps1` to align with a local-first testing workflow.
    *   The script now automatically calls `build_menu.py` after generating a draft to update the site navigation.
    *   It now commits both the new draft *and* the updated `mkdocs.yml` to the local repository.
    *   Crucially, the automatic `git push` has1been removed to allow for batching changes and local testing before manual deployment.
*   **Bug Fixes & System Diagnostics:**
    *   Resolved a `PermissionError` in `build_menu.py` during directory cleanup.
    *   Fixed a working directory issue in `build-site.ps1` to ensure `mkdocs build` runs correctly.
    *   Improved the dummy questions in `create_new_pqq.py` to be more explicit, aiding AI processing.
    *   Diagnosed repeated failures in the `Invoke-GeminiQuestionExtraction` step. The root cause was identified as hitting the Gemini API's free-tier rate limit (`429 You exceeded your current quota`). The project is currently blocked pending quota reset or a new API key.

## Project Description and Architecture
(Generated by Gemini analysis on 2025-12-11)

This project is a sophisticated automation pipeline designed to streamline the creation and management of Pre-Qualification Questionnaire (PQQ) responses. It leverages AI for content processing and a static site generator for presentation. The system is built around two primary, distinct workflows: PQQ Processing and Website Generation.

### Workflow 1: PQQ Processing (Automated)
This workflow automates the generation of draft PQQ responses from source documents.

1.  **Trigger**: The process begins when a user places a PQQ document (.pdf or .docx) into the `/incoming` directory and manually executes the `run-pqq-manager.ps1` script.
2.  **Orchestration**: The `run-pqq-manager.ps1` script orchestrates the entire workflow. It detects new files and calls the Python-based AI processor for the heavy lifting.
3.  **AI Processing (`gemini_processor.py`)**:
    *   **Text Extraction**: Extracts raw text from the source document.
    *   **Question Identification**: Sends the extracted text to the Gemini API to identify and list out all questions.
    *   **Evidence Matching**: The script then sends these questions, along with the entire content of the `/evidence` library, to the Gemini API. The AI matches each question with the most relevant answer from the evidence library and returns a structured response.
4.  **Draft Generation**: The orchestrator script assembles the questions and their corresponding AI-selected answers into a new Markdown file.
5.  **Output & Archiving**: The final draft is saved to the `/drafts` directory. The change is automatically committed to Git, and the original source document is moved to `/incoming/processed` for record-keeping.

### Workflow 2: Website Generation (Semi-Automated)
This workflow builds a searchable static website from the generated drafts and the evidence library.

1.  **Trigger**: A user runs the `build-site.ps1` script.
2.  **Content Aggregation (`build_menu.py`)**: The build script first executes `build_menu.py`. This Python script acts as a pre-processor, cleaning the `/docs` directory and then populating it by copying all content from three sources: `/docs_source` (static pages like this guide), `/drafts` (all PQQ responses), and `/evidence` (the complete knowledge base).
3.  **Site Build**: `build-site.ps1` then invokes `mkdocs build`, which uses the content in the now-prepared `/docs` directory to generate the final static HTML site in the `/site` directory.
4.  **Deployment**: The site can be deployed to GitHub Pages via a command-line switch in the build script.

### Key Architectural Insights
*   **Separation of Concerns**: The architecture effectively separates the AI processing logic (Python) from the high-level workflow orchestration (PowerShell).
*   **Ephemeral Build Directory**: The `/docs` directory is treated as a temporary build artifact, recreated from multiple sources on each build. This is a robust pattern that prevents source-of-truth conflicts.
*   **Data-Driven Workflow**: The directory structure (`incoming`, `evidence`, `drafts`, `docs`, `site`) clearly defines the flow of data through the system.
*   **Manual Bottleneck**: The `mkdocs.yml` file contains a **hardcoded navigation menu**. This means that when a new PQQ draft is generated, it will not automatically appear on the website. A developer must manually edit the `nav` section of `mkdocs.yml` to include a link to the new file. The `build_menu.py` script's name is misleading; it only stages files, it does not dynamically generate the navigation menu itself.
*   **Test Utility**: The `create_new_pqq.py` script is a helpful developer utility for creating dummy `.docx` files to test the PQQ processing workflow.

## 2025-12-11

*   **Refactored Project Structure:**
    *   Separated the source markdown files from the final `docs` directory used by MkDocs.
    *   Created a new `docs_source` directory to hold the static markdown files.
    *   Updated the `build_menu.py` script to prepare the `docs` directory by copying files from `drafts`, `evidence`, and `docs_source`.
    *   Updated the `mkdocs.yml` file to reflect the new structure of the `docs` directory.
    *   Added `docs/` to the `.gitignore` file.
*   **Resolved API Key Issue:**
    *   Modified `gemini_processor.py` to read the `PQQ_API_KEY` from a `.env` file instead of relying on an environment variable.
    *   Added `python-dotenv` to `requirements.txt`.
    *   Created a `.env` file with a placeholder for the API key and added it to `.gitignore`.
    *   Removed the explicit API key check from `run-pqq-manager.ps1`.
*   **Improved `create_new_pqq.py`:**
    *   Modified the script to accept an optional filename as a command-line argument.
*   **Testing:**
    *   Successfully processed `New_PQQ_Test.docx` and `Another_PQQ_Test.docx` using the `run-pqq-manager.ps1` script.
